import boto3
import json
import os
import datetime
import concurrent.futures

# --- CONFIGURATION ---
SES_REGION = os.environ.get('SES_REGION', 'ap-southeast-1')
SENDER = os.environ.get('SENDER_EMAIL')
RECIPIENT_STRING = os.environ.get('RECIPIENT_EMAIL')
DAYS_THRESHOLD_SNAPSHOTS = 30
DAYS_THRESHOLD_STOPPED_EC2 = 7

# --- ROBUST FALLBACK PRICES (USD/Month) ---
FALLBACKS = {
    'ebs_gp3': 0.08,      # Per GB
    'ebs_io2': 0.125,     # Per GB
    'rds_storage': 0.115, # Per GB
    'snapshot': 0.05,     # Per GB
    'eip': 3.65,          # Flat Monthly ($0.005/hr)
    'alb': 16.42,         # Flat Monthly ($0.0225/hr)
    'nlb': 16.42          # Flat Monthly
}

# --- CLIENTS ---
ses = boto3.client('ses', region_name=SES_REGION)
pricing_client = boto3.client('pricing', region_name='us-east-1')
ssm = boto3.client('ssm', region_name='us-east-1')

class PricingResolver:
    """
    Fetches live AWS pricing with strict unit validation.
    """
    def __init__(self):
        self.location_cache = {}
        self.price_cache = {}

    def get_region_long_name(self, region_code):
        if region_code in self.location_cache: 
            return self.location_cache[region_code]
        try:
            param = f"/aws/service/global-infrastructure/regions/{region_code}/longName"
            val = ssm.get_parameter(Name=param)['Parameter']['Value']
            self.location_cache[region_code] = val
            return val
        except Exception:
            return None

    def get_price(self, region, service, filters, required_unit=None):
        cache_key = f"{region}_{service}_{str(filters)}_{required_unit}"
        if cache_key in self.price_cache: 
            return self.price_cache[cache_key]

        location = self.get_region_long_name(region)
        if not location: return 0.0

        final_filters = filters + [{'Type': 'TERM_MATCH', 'Field': 'location', 'Value': location}]
        
        try:
            response = pricing_client.get_products(ServiceCode=service, Filters=final_filters, MaxResults=5)
            for item in response['PriceList']:
                data = json.loads(item)
                for term in data['terms']['OnDemand'].values():
                    for dim in term['priceDimensions'].values():
                        unit = dim['unit']
                        price = float(dim['pricePerUnit']['USD'])
                        
                        if required_unit and required_unit not in unit:
                            continue
                            
                        if price > 0:
                            self.price_cache[cache_key] = price
                            return price
        except Exception:
            pass
        return 0.0

pricer = PricingResolver()

# --- HELPERS ---
def get_days_since(time_val):
    if not time_val: return 0
    now = datetime.datetime.now(datetime.timezone.utc)
    if time_val.tzinfo is None: time_val = time_val.replace(tzinfo=datetime.timezone.utc)
    return (now - time_val).days

def get_console_link(region, service, resource_id):
    base = f"https://{region}.console.aws.amazon.com"
    if service == 'ec2': return f"{base}/ec2/v2/home?region={region}#InstanceDetails:instanceId={resource_id}"
    elif service == 'ebs': return f"{base}/ec2/v2/home?region={region}#VolumeDetails:volumeId={resource_id}"
    elif service == 'rds': return f"{base}/rds/home?region={region}#database:id={resource_id};is-cluster=false"
    elif service == 'snapshot': return f"{base}/ec2/v2/home?region={region}#SnapshotDetails:snapshotId={resource_id}"
    elif service == 'elb': return f"{base}/ec2/v2/home?region={region}#LoadBalancers:search={resource_id}"
    return f"{base}/console"

def create_finding(region, resource_type, resource_id, meta, cost, service_slug):
    return {
        'region': region,
        'type': resource_type,
        'id': resource_id,
        'meta': meta,
        'cost': float(f"{cost:.2f}"), # Ensure strictly 2 decimal float
        'link': get_console_link(region, service_slug, resource_id)
    }

# --- SCANNING LOGIC ---
def scan_region(region):
    ec2 = boto3.client('ec2', region_name=region)
    elbv2 = boto3.client('elbv2', region_name=region)
    rds = boto3.client('rds', region_name=region)
    findings = []

    # 1. STOPPED RDS
    try:
        dbs = rds.describe_db_instances()
        for db in dbs['DBInstances']:
            if db['DBInstanceStatus'] == 'stopped':
                size = db['AllocatedStorage']
                storage_type = db.get('StorageType', 'gp2')
                api_storage_type = 'Provisioned IOPS' if 'io' in storage_type else 'General Purpose'
                price = pricer.get_price(region, 'AmazonRDS', [
                    {'Type': 'TERM_MATCH', 'Field': 'productFamily', 'Value': 'Database Storage'},
                    {'Type': 'TERM_MATCH', 'Field': 'volumeType', 'Value': api_storage_type}
                ], 'GB-Mo') or FALLBACKS['rds_storage']
                
                findings.append(create_finding(region, 'Stopped RDS', db['DBInstanceIdentifier'], 
                                               f"{size} GB ({storage_type})", size * price, 'rds'))
    except Exception: pass

    # 2. UNATTACHED EBS
    try:
        vols = ec2.describe_volumes(Filters=[{'Name': 'status', 'Values': ['available']}])
        for v in vols['Volumes']:
            v_type = v['VolumeType']
            api_type = 'Provisioned IOPS' if 'io' in v_type else 'General Purpose'
            fallback = FALLBACKS['ebs_io2'] if 'io' in v_type else FALLBACKS['ebs_gp3']
            price = pricer.get_price(region, 'AmazonEC2', [
                {'Type': 'TERM_MATCH', 'Field': 'productFamily', 'Value': 'Storage'},
                {'Type': 'TERM_MATCH', 'Field': 'volumeType', 'Value': api_type}
            ], 'GB-Mo') or fallback
            
            findings.append(create_finding(region, 'Unattached EBS', v['VolumeId'], 
                                           f"{v['Size']} GB | {v_type}", v['Size'] * price, 'ebs'))
    except Exception: pass

    # 3. ORPHAN SNAPSHOTS
    try:
        account_id = boto3.client('sts').get_caller_identity()['Account']
        snaps = ec2.describe_snapshots(OwnerIds=[account_id])
        images = ec2.describe_images(Owners=[account_id])
        active_snaps = {b['Ebs']['SnapshotId'] for i in images['Images'] for b in i.get('BlockDeviceMappings', []) if 'Ebs' in b}
        price = pricer.get_price(region, 'AmazonEC2', [
             {'Type': 'TERM_MATCH', 'Field': 'productFamily', 'Value': 'Storage Snapshot'}
        ], 'GB-Mo') or FALLBACKS['snapshot']

        for s in snaps['Snapshots']:
            if s['SnapshotId'] not in active_snaps:
                age = get_days_since(s['StartTime'])
                if age > DAYS_THRESHOLD_SNAPSHOTS:
                    findings.append(create_finding(region, 'Old Snapshot', s['SnapshotId'], 
                                                   f"{s['VolumeSize']} GB | {age} Days Old", s['VolumeSize'] * price, 'snapshot'))
    except Exception: pass

    # 4. IDLE LOAD BALANCERS
    try:
        lbs = elbv2.describe_load_balancers()
        alb_price = pricer.get_price(region, 'AmazonEC2', [
            {'Type': 'TERM_MATCH', 'Field': 'productFamily', 'Value': 'Load Balancer-Application'},
            {'Type': 'TERM_MATCH', 'Field': 'locationType', 'Value': 'AWS Region'}
        ], 'Hrs') or FALLBACKS['alb']

        for lb in lbs['LoadBalancers']:
            tgs = elbv2.describe_target_groups(LoadBalancerArn=lb['LoadBalancerArn'])
            active = any(
                t['TargetHealth']['State'] in ['healthy', 'initial']
                for tg in tgs['TargetGroups']
                for t in elbv2.describe_target_health(TargetGroupArn=tg['TargetGroupArn'])['TargetHealthDescriptions']
            )
            if not active:
                findings.append(create_finding(region, 'Idle Load Balancer', lb['LoadBalancerName'], 
                                               "No Healthy Targets", alb_price * 730, 'elb'))
    except Exception: pass

    # 5. UNUSED EIPs
    try:
        addrs = ec2.describe_addresses()
        for ip in addrs['Addresses']:
            if 'AssociationId' not in ip:
                 findings.append(create_finding(region, 'Unused Elastic IP', ip['PublicIp'], 
                                                "Not attached", FALLBACKS['eip'], 'ec2'))
    except Exception: pass

    # 6. STOPPED EC2
    try:
        instances = ec2.describe_instances(Filters=[{'Name': 'instance-state-name', 'Values': ['stopped']}])
        for r in instances['Reservations']:
            for inst in r['Instances']:
                storage_cost = 0
                vol_ids = []
                for bdm in inst.get('BlockDeviceMappings', []):
                    if 'Ebs' in bdm:
                        try:
                            v_id = bdm['Ebs']['VolumeId']
                            vol = ec2.describe_volumes(VolumeIds=[v_id])['Volumes'][0]
                            storage_cost += vol['Size'] * FALLBACKS['ebs_gp3'] 
                            vol_ids.append(v_id)
                        except: pass
                if storage_cost > 0:
                     findings.append(create_finding(region, 'Stopped EC2', inst['InstanceId'], 
                                                    f"Holding {len(vol_ids)} EBS vols", storage_cost, 'ec2'))
    except Exception: pass

    return findings

# --- REPORTING ---
def send_email_report(findings, total_cost):
    if not RECIPIENT_STRING: return
    recipients = [e.strip() for e in RECIPIENT_STRING.split(',') if e.strip()]
    findings.sort(key=lambda x: x['cost'], reverse=True)
    
    # Simple HTML Table Row Generation
    rows = ""
    for f in findings:
        rows += f"""<tr>
            <td>{f['type']}</td>
            <td>{f['region']}</td>
            <td>{f['id']}</td>
            <td>{f['meta']}</td>
            <td><b>${f['cost']:.2f}</b></td>
        </tr>"""

    html_body = f"""<html><body>
    <h2>Weekly Waste Report</h2>
    <h3>Total Potential Savings: <span style="color:red">${total_cost:.2f}</span></h3>
    <table border="1" cellpadding="5" cellspacing="0">
        <tr style="background:#eee"><th>Type</th><th>Region</th><th>ID</th><th>Details</th><th>Cost</th></tr>
        {rows}
    </table>
    </body></html>"""

    try:
        ses.send_email(
            Source=SENDER,
            Destination={'ToAddresses': recipients},
            Message={
                'Subject': {'Data': f"AWS Waste Report: ${total_cost:.2f}", 'Charset': 'UTF-8'},
                'Body': {'Html': {'Data': html_body, 'Charset': 'UTF-8'}}
            }
        )
    except Exception as e:
        print(f"SES Error: {e}")

# --- MAIN HANDLER ---
def lambda_handler(event, context):
    print("--- Starting FinOps Scan ---")
    
    # 1. Get Regions
    try:
        ec2_global = boto3.client('ec2', region_name='us-east-1')
        regions = [r['RegionName'] for r in ec2_global.describe_regions()['Regions']]
    except Exception:
        regions = ['us-east-1', 'us-east-2', 'eu-west-1']

    all_findings = []
    
    # 2. Parallel Scan
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        futures = [executor.submit(scan_region, r) for r in regions]
        for f in concurrent.futures.as_completed(futures):
            try:
                all_findings.extend(f.result())
            except Exception: pass

    total_waste = sum(f['cost'] for f in all_findings)

    # 3. GRAFANA EXPORT (JSON LOGGING)
    # This prints each finding as a separate JSON line in CloudWatch
    print("--- GRAFANA_START ---")
    for f in all_findings:
        # Add timestamp for Time Series visualization
        f['timestamp'] = datetime.datetime.now().isoformat()
        f['MetricName'] = 'WasteFinding'
        print(json.dumps(f))
    print("--- GRAFANA_END ---")

    # 4. Email Report
    if total_waste > 0:
        send_email_report(all_findings, total_waste)
        
    return {"status": "Complete", "savings": total_waste}